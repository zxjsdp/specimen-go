package web

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"net/http"
	"net/url"
	"strings"

	"log"

	"regexp"

	"github.com/PuerkitoBio/goquery"
	"github.com/zxjsdp/specimen-go/config"
	"github.com/zxjsdp/specimen-go/entities"
	"github.com/zxjsdp/specimen-go/utils"
)

// ï¼ˆgoroutineï¼‰æ ¹æ®æ‹‰ä¸åè·å–ç½‘ç»œä¿¡æ¯ map
func GenerateWebInfoMap(latinNames []string) map[string]entities.WebInfo {
	webInfoMap := make(map[string]entities.WebInfo)
	latinNames = utils.RemoveDuplicates(latinNames)
	size := len(latinNames)

	jobChannel := make(chan string, size)
	resultWebInfoChannel := make(chan entities.WebInfo, size)

	for i := 1; i <= config.WorkerPoolSize; i++ {
		go worker(i, jobChannel, resultWebInfoChannel)
	}

	for _, latinName := range latinNames {
		jobChannel <- latinName
	}

	close(jobChannel)

	for i := 1; i <= size; i++ {
		webInfo := <-resultWebInfoChannel
		webInfoMap[webInfo.FullLatinName] = webInfo
	}

	return webInfoMap
}

func worker(id int, jobs <-chan string, results chan<- entities.WebInfo) {
	for latinName := range jobs {
		//log.Println("worker", id, "started job", latinName)
		webInfo := GenerateWebInfo(latinName)
		//log.Println("worker", id, "finished job", latinName)
		results <- webInfo
	}
}

// ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰æ ¹æ®æ‹‰ä¸åè·å–ç½‘ç»œä¿¡æ¯ map
func GenerateWebInfoMapSync(latinNames []string) map[string]entities.WebInfo {
	webInfoMap := make(map[string]entities.WebInfo)

	latinNames = utils.RemoveDuplicates(latinNames)
	for i, latinName := range latinNames {
		log.Println(i + 1)
		webInfoMap[latinName] = GenerateWebInfo(latinName)
	}

	return webInfoMap
}

// è·å–å¹¶å¤„ç†ç½‘ç»œä¿¡æ¯
func GenerateWebInfo(latinNameString string) entities.WebInfo {
	latinName := utils.ParseLatinName(latinNameString)
	if len(latinName.Species) == 0 || strings.HasSuffix(latinName.Species, config.AmbiguousSpeciesName) {
		// è‹¥æ²¡æœ‰ç§åï¼Œæˆ–è€…ç§åä¸º sp.ï¼Œåˆ™ä»…é‰´å®šåˆ°å±ï¼Œæ— æ³•ä»ç½‘ç»œè·å–åˆ°æ¯”è¾ƒç²¾ç¡®çš„ç‰©ç§ä¿¡æ¯
		return entities.WebInfo{
			FullLatinName: latinNameString,
			Morphology:    entities.Morphology{},
			NamePublisher: "",
			Habitat:       "",
		}
	}

	fmt.Printf("    ğŸŒ [%s]        å¼€å§‹ä»ç½‘ç»œè·å–ã€Œç‰©ç§ä¿¡æ¯ã€\n", latinNameString)
	frpsspno, frpsspclassid, paragraphs := parseParagraphs(latinName)
	fmt.Printf("    ğŸ’š [%s]        è·å–åˆ°ã€Œç‰©ç§ä¿¡æ¯ã€\n", latinNameString)

	fmt.Printf("    ğŸŒ€ [%s]        å¼€å§‹å¯»æ‰¾ã€Œæœ€åŒ¹é…æ®µè½ã€\n", latinNameString)
	bestMatchParagraph := pickBestMatchedParagraph(latinNameString, paragraphs)
	fmt.Printf("    ğŸ’š [%s]        å¯»æ‰¾ã€Œæœ€åŒ¹é…æ®µè½ã€å®Œæˆ\n", latinNameString)

	fmt.Printf("    ğŸŒ€ [%s]        å¼€å§‹ä»æœ€åŒ¹é…æ®µè½ä¸­ã€Œæå–å½¢æ€æè¿°ä¿¡æ¯ã€\n", latinNameString)
	morphology := getMorphologyFromMultipleParagraphs([]string{bestMatchParagraph})
	fmt.Printf("    ğŸ’š [%s]        ä»æœ€åŒ¹é…æ®µè½ä¸­ã€Œæå–å½¢æ€æè¿°ä¿¡æ¯ã€ç»“æŸ\n", latinNameString)

	fmt.Printf("    ğŸŒ [%s]        å¼€å§‹ä»ç½‘ç»œè·å–ã€Œå‘½åäººã€ä¿¡æ¯\n", latinNameString)
	namePublisher := parseNamePublisher(latinName)
	fmt.Printf("    ğŸ’š [%s %s]        è·å–åˆ°ã€Œå‘½åäººã€ä¿¡æ¯ \n", latinNameString, namePublisher)

	fmt.Printf("    ğŸŒ [%s]        å¼€å§‹ä»ç½‘ç»œè·å–ã€Œç‰©ç§åˆ†ç±»ï¼ˆTexomonyï¼Œç•Œé—¨çº²ç›®ç§‘å±ç§ï¼‰ã€ä¿¡æ¯\n", latinNameString)
	phylum, class, order, family, genus := parseTaxonomyInfo(latinName, frpsspno, frpsspclassid)
	fmt.Printf("    ğŸ’š [%s %s]        è·å–åˆ°ã€Œç‰©ç§åˆ†ç±»ï¼ˆTexomonyï¼Œç•Œé—¨çº²ç›®ç§‘å±ç§ï¼‰ã€ä¿¡æ¯: â†’ ã€Œ%s %s %s %s %sã€\n", latinNameString, namePublisher, phylum, class, order, family, genus)

	return entities.WebInfo{
		FullLatinName: latinNameString,
		Morphology:    morphology,
		NamePublisher: namePublisher,
		Family:        family,
		Habitat:       "",
	}
}

// é€‰æ‹©æœ€ç¬¦åˆæ¡ä»¶çš„æ®µè½
func pickBestMatchedParagraph(latinNameString string, paragraphs []string) string {
	if len(paragraphs) == 0 {
		fmt.Printf("    ğŸ’” %s | %s | resp.Body ä¸ºç©º!\n", latinNameString, "pickBestMatchedParagraph")
		return ""
	}

	// TODO, éœ€è¦å®ç°ï¼šæ£€æŸ¥æ‰€æœ‰ç»„åˆï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå…¨éƒ¨åŒ…å«çš„æ®µè½
	// [A, B, C, D, E], ... æ˜¯å¦æœ‰å…¨éƒ¨åŒ…å«çš„æ®µè½
	// [A, B, C, D], [A, B, C, E], ... æ˜¯å¦æœ‰å…¨éƒ¨åŒ…å«çš„æ®µè½
	// [A, B, C], [A, B, D], ... } ... æ˜¯å¦æœ‰å…¨éƒ¨åŒ…å«çš„æ®µè½
	// [A, B], [A, C], ... } ... æ˜¯å¦æœ‰å…¨éƒ¨åŒ…å«çš„æ®µè½

	// ç›®å‰å…ˆä½¿ç”¨å·²æœ‰çš„é€»è¾‘
	paragraphContainsAllKeywords := ""
	for _, paragraph := range paragraphs {
		paragraphContainsAllKeywords = checkIfParagraphThatContainsAllKeywords(paragraph, config.AllKeywords)
		if paragraphContainsAllKeywords != "" {
			return paragraph
		}
	}

	for _, paragraph := range paragraphs {
		paragraphContainsAllKeywords = checkIfParagraphThatContainsAllKeywords(paragraph, config.ModerateKeywords)
		if paragraphContainsAllKeywords != "" {
			return paragraph
		}
	}

	for _, paragraph := range paragraphs {
		paragraphContainsAllKeywords = checkIfParagraphThatContainsAllKeywords(paragraph, config.RelaxedKeywords)
		if paragraphContainsAllKeywords != "" {
			return paragraph
		}
	}

	return paragraphContainsAllKeywords
}

// æ£€æµ‹æ®µè½æ˜¯å¦æ»¡è¶³ç‰¹å®šçš„å…³é”®å­—æ¡ä»¶
func checkIfParagraphThatContainsAllKeywords(paragraph string, keywords []string) string {
	if strings.TrimSpace(paragraph) == "" {
		return ""
	}
	allKeywordInParagraph := true
	for _, keyword := range keywords {
		if !strings.Contains(paragraph, keyword) {
			allKeywordInParagraph = false
		}
		if !allKeywordInParagraph {
			break
		}
	}
	if allKeywordInParagraph {
		return paragraph
	}
	return ""
}

// ä»æ‰€æœ‰æ®µè½é‡Œæå–æ¤ç‰©çš„å„ç±»å½¢æ€ä¿¡æ¯
func getMorphologyFromMultipleParagraphs(paragraphs []string) entities.Morphology {
	morphologySlice := make([]entities.Morphology, 0)
	for _, paragraph := range paragraphs {
		morphologySlice = append(morphologySlice, parseMorphologyFromContent(paragraph))
	}

	bodyHeightInfoSlice := make([]string, 0)
	DBHInfoSlice := make([]string, 0)
	stemInfoSlice := make([]string, 0)
	leafInfoSlice := make([]string, 0)
	flowerInfoSlice := make([]string, 0)
	fruitInfoSlice := make([]string, 0)
	hostInfoSlice := make([]string, 0)

	for _, morphology := range morphologySlice {
		bodyHeightInfoSlice = append(bodyHeightInfoSlice, morphology.BodyHeight)
		DBHInfoSlice = append(DBHInfoSlice, morphology.DBH)
		stemInfoSlice = append(DBHInfoSlice, morphology.Stem)
		leafInfoSlice = append(leafInfoSlice, morphology.Leaf)
		flowerInfoSlice = append(flowerInfoSlice, morphology.Flower)
		fruitInfoSlice = append(fruitInfoSlice, morphology.Fruit)
		hostInfoSlice = append(hostInfoSlice, morphology.Host)
	}

	finalMorphology := entities.Morphology{
		BodyHeight: filterAndCombineMorphologyInfo(bodyHeightInfoSlice),
		DBH:        filterAndCombineMorphologyInfo(DBHInfoSlice),
		Stem:       filterAndCombineMorphologyInfo(stemInfoSlice),
		Leaf:       filterAndCombineMorphologyInfo(leafInfoSlice),
		Flower:     filterAndCombineMorphologyInfo(flowerInfoSlice),
		Fruit:      filterAndCombineMorphologyInfo(fruitInfoSlice),
		Host:       filterAndCombineMorphologyInfo(hostInfoSlice),
	}

	return finalMorphology
}

// æ‹¼æ¥å½¢æ€ä¿¡æ¯
func filterAndCombineMorphologyInfo(infoSlice []string) string {
	resultSlice := make([]string, 0)
	for _, each := range infoSlice {
		each = strings.TrimSpace(each)
		if len(each) > 0 {
			resultSlice = append(resultSlice, each)
		}
	}

	resultInfo := strings.Join(resultSlice, config.DefaultSeparator)
	if len(resultInfo) > 0 {
		return resultInfo + "ã€‚"
	}
	return resultInfo
}

// ä»æ®µè½ä¸­è§£æå½¢æ€ä¿¡æ¯
func parseMorphologyFromContent(paragraph string) entities.Morphology {
	bodyHeightInfo := strings.Join(config.BodyHeightRegexp.FindAllString(paragraph, -1), config.DefaultSeparator) // ä½“é«˜
	DBHInfo := strings.Join(config.DBHRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)               // èƒ¸å¾„
	stemInfo := strings.Join(config.StemRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)             // èŒ
	leafInfo := strings.Join(config.LeafRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)             // å¶
	flowerInfo := strings.Join(config.FlowerRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)         // èŠ±
	fruitInfo := strings.Join(config.FruitRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)           // æœå®
	hostInfo := strings.Join(config.HostRegexp.FindAllString(paragraph, -1), config.DefaultSeparator)             // å¯„ä¸»

	return entities.Morphology{
		BodyHeight: bodyHeightInfo,
		DBH:        DBHInfo,
		Stem:       stemInfo,
		Leaf:       leafInfo,
		Flower:     flowerInfo,
		Fruit:      fruitInfo,
		Host:       hostInfo,
	}
}

// ã€Œå‘½åäººã€ä¿¡æ¯è§£æ
func parseNamePublisher(latinName entities.LatinName) (namePublisher string) {
	baseUrl := config.URLPrefixEFLORA + strings.Join(latinName.Elements, config.URLBlankSeparator) + config.URLSuffix
	resp, err := http.Get(baseUrl)
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseNamePublisher http.Get", err)
	}
	defer resp.Body.Close()

	spnoRegexp, err := regexp.Compile(fmt.Sprintf(config.SpnoRegexpTemplate))
	if err != nil {
		return ""
	}

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return ""
	}
	spnoSlice := spnoRegexp.FindAllString(string(body), -1)
	if len(spnoSlice) == 0 {
		return ""
	}
	spnoInfo := spnoSlice[0]
	spnoInfoSlice := strings.Split(spnoInfo, "\"")
	if len(spnoInfoSlice) != 3 {
		return ""
	}

	spno := spnoInfoSlice[1]

	// ã€Œæ‹‰ä¸åã€ä¿¡æ¯æŸ¥è¯¢ data æ ¼å¼ï¼Œæ³¨æ„æ­¤ spno ä¸ frpsspno ä¸ºä¸åŒçš„ ID
	//     - spno: ä»ã€Œhttp://www.iplant.cn/ashx/getfrps.ashx?key=Cephalotaxus+fortuneiã€API è¿”å›çš„ç»“æœä¸­å– var spno = "10726"
	// ç¤ºä¾‹ï¼šspno=10726
	resp, err = http.PostForm(config.LatinApiUrl, url.Values{"spno": {spno}})
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseNamePublisher http.PostForm", err)
	}
	defer resp.Body.Close()

	// ç¤ºä¾‹: <span class='font20'><b>Cephalotaxus</b></span> <span class='font20'><b>fortunei</b></span> Hooker
	body, err = ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseNamePublisher http.PostForm", err)
		return ""
	}

	contentSlice := strings.Split(string(body), config.NamePublisherSeparator)
	if len(contentSlice) > 0 {
		namePublisher = strings.TrimSpace(contentSlice[len(contentSlice)-1])
	}

	return namePublisher
}

// ä»ç½‘ç»œä¿¡æ¯ä¸­æå–ã€Œç”Ÿç‰©åˆ†ç±»ï¼ˆé—¨çº²ç›®ç§‘å±ï¼‰ã€ä¿¡æ¯
// ç•Œï¼ˆKingdomï¼‰ã€é—¨ï¼ˆPhylumï¼‰ã€çº²ï¼ˆClassï¼‰ã€ç›®ï¼ˆOrderï¼‰ã€ç§‘ï¼ˆFamilyï¼‰ã€å±ï¼ˆGenusï¼‰ã€ç§ï¼ˆSpeciesï¼‰
func parseTaxonomyInfo(latinName entities.LatinName, frpsspno string, frpsspclassid string) (phylum string, class string, order string, family string, genus string) {
	if len(frpsspno) == 0 || len(frpsspclassid) == 0 {
		fmt.Printf("    ğŸ’” %s | %s \n", latinName.LatinNameString, "parseTaxonomyInfo frpsspno æˆ– frpsspclassid ä¸ºç©º! "+"frpsspno: "+frpsspno+", frpsspclassid: "+frpsspclassid)
		return "", "", "", "", ""
	}

	// ã€Œç‰©ç§åˆ†ç±»ï¼ˆTexomonyï¼Œç•Œé—¨çº²ç›®ç§‘å±ç§ï¼‰ã€ä¿¡æ¯æŸ¥è¯¢ data æ ¼å¼ï¼Œ
	//     - spno: ä»ã€Œè¯¦ç»†æè¿°ã€API è¿”å›çš„ç»“æœä¸­å– frpsspno
	//     - spclassid: ä»ã€Œè¯¦ç»†æè¿°ã€API è¿”å›çš„ç»“æœä¸­å– frpsspclassid
	// ç¤ºä¾‹ï¼šspno=52&spclassid=24
	resp, err := http.PostForm(config.DetailedCategoryApiUrl, url.Values{"spno": {frpsspno}, "spclassid": {frpsspclassid}})
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseTaxonomyInfo http.PostForm", err)
	}
	defer resp.Body.Close()

	var responseMap map[string]string
	err = json.NewDecoder(resp.Body).Decode(&responseMap)
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseTaxonomyInfo json.NewDecoder", err)
	}

	frpsclasstxt := responseMap[config.FrpsclasstxtKeyInResponseMap]

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(frpsclasstxt))
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseTaxonomyInfo goquery.NewDocumentFromReader", err)
	}

	doc.Find("a").Each(func(i int, s *goquery.Selection) {
		text := s.Text()
		if strings.Contains(text, config.PhylumKeyword) {
			phylum = strings.TrimSpace(text)
		} else if strings.Contains(text, config.ClassKeyword) {
			class = strings.TrimSpace(text)
		} else if strings.Contains(text, config.OrderKeyword) {
			order = strings.TrimSpace(text)
		} else if strings.Contains(text, config.FamilyKeyword) {
			family = strings.TrimSpace(text)
		} else if strings.Contains(text, config.GenusKeyword) {
			genus = strings.TrimSpace(text)
		}
	})

	return phylum, class, order, family, genus
}

// ä»ç½‘ç»œ API è¿”å›çš„è¯¦ç»†æ®µè½ä¿¡æ¯ä¸­ï¼Œæå–ã€ŒèŒã€ã€ã€Œå¶ã€ã€ã€ŒèŠ±ã€ã€ã€Œæœã€ç­‰ä¿¡æ¯
func parseParagraphs(latinName entities.LatinName) (frpsspno string, frpsspclassid string, paragraphs []string) {
	paragraphs = []string{}

	apiUrl := config.DetailedDescriptionApiURLPrefix + strings.Join(latinName.Elements, config.APIURLBlankSeparator)
	resp, err := http.Get(apiUrl)
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseParagraphs http.Get", err)
	}

	var responseMap map[string]string
	err = json.NewDecoder(resp.Body).Decode(&responseMap)
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s %v \n", latinName.LatinNameString, "parseParagraphs json.NewDecoder", err)
		return "", "", []string{}
	}
	defer resp.Body.Close()

	frpsspno = responseMap[config.FrpsspnoKeyInResponseMap]
	frpsspclassid = responseMap[config.FrpsspclassidKeyInResponseMap]
	frpsdesc := responseMap[config.FrpsdescKeyInResponseMap]

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(frpsdesc))
	if err != nil {
		fmt.Printf("    ğŸ’” %s | %s: %v \n", latinName.LatinNameString, "parseParagraphs goquery.NewDocumentFromReader", err)
	}

	doc.Find("p").Each(func(i int, s *goquery.Selection) {
		paragraphs = append(paragraphs, s.Text())
	})

	return frpsspno, frpsspclassid, paragraphs
}
